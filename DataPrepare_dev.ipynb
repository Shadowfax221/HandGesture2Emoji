{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "NUM_SAMPLES = 100\n",
    "DATASET_DIR = \"E:/MyDatasets/hagrid_dataset_512\"\n",
    "ANNOTATIONS_DIR = \"C:/Users/Ian/git/553.806_Capstone_HandGesture/annotations/test\"\n",
    "LABELS = ['call', 'dislike', 'fist', 'like', 'mute', 'ok', 'one', 'palm', 'peace', 'rock', 'stop', 'stop_inverted']     # 12 gestures: 🤙, 👎, ✊, 👍, 🤐, 👌, ☝, 🖐, ✌, 🤘, ✋, 🤚\n",
    "\n",
    "\n",
    "# Check if the point (x, y) is within the bounding box.\n",
    "def is_point_in_bbox(x, y, bbox, margin=0.01):\n",
    "    tl_x, tl_y, width, height = bbox\n",
    "    ext_tl_x = tl_x - margin\n",
    "    ext_tl_y = tl_y - margin\n",
    "    ext_br_x = tl_x + width + margin\n",
    "    ext_br_y = tl_y + height + margin\n",
    "    return ext_tl_x <= x <= ext_br_x and ext_tl_y <= y <= ext_br_y\n",
    "\n",
    "\n",
    "\n",
    "# STEP 1: Create an HandLandmarker object.\n",
    "base_options = python.BaseOptions(model_asset_path='models/hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options, num_hands=2)\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "csv_filename = 'keypoint.csv'\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    \n",
    "    # STEP 2: Load the input image.\n",
    "    for label in LABELS:\n",
    "        with open(os.path.join(ANNOTATIONS_DIR, f\"{label}.json\"), 'r') as file:\n",
    "            annotations = json.load(file)\n",
    "        \n",
    "        samples_cnt = 0\n",
    "        while samples_cnt < NUM_SAMPLES:\n",
    "            image_name = random.choice(list(annotations.keys()))\n",
    "            image_path = os.path.join(DATASET_DIR, label, f'{image_name}.jpg')\n",
    "            image = mp.Image.create_from_file(image_path)\n",
    "\n",
    "            # STEP 3: Detect hand landmarks from the input image.\n",
    "            detection_result = detector.detect(image)\n",
    "\n",
    "            # STEP 4: Write hand landmark into csv\n",
    "            annotations_labels = annotations[image_name]['labels']\n",
    "            annotations_bboxes = annotations[image_name]['bboxes']\n",
    "            gesture_bboxes = annotations_bboxes[annotations_labels.index(label)]\n",
    "\n",
    "            label_dict = {label: i for i, label in enumerate(LABELS)}\n",
    "            for hand_landmarks in detection_result.hand_landmarks:\n",
    "                row = [label_dict[label]] \n",
    "                for landmark in hand_landmarks:\n",
    "                    if is_point_in_bbox(landmark.x, landmark.y, gesture_bboxes):\n",
    "                        row.extend([landmark.x, landmark.y, landmark.z])        # may add landmark.z\n",
    "                \n",
    "                if len(row) == 64:\n",
    "                    csvwriter.writerow(row)\n",
    "                    samples_cnt += 1\n",
    "        print(f\"Writen {samples_cnt} samples of {label}\")\n",
    "\n",
    "print(\"CSV file has been created:\", csv_filename)\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
